





import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix
import plotly.figure_factory as ff








X_test = pd.read_csv("X_test.csv", delimiter=',')
X_train = pd.read_csv("X_train_balanced.csv", delimiter=',')
y_test = pd.read_csv("y_test.csv", delimiter=',')
y_train = pd.read_csv("y_train_balanced.csv", delimiter=',')





X_test


y_test


y_train


X_train











# Contar o número de exemplos de cada classe em y_train
train_balance = y_train.value_counts()
print("Balanceamento em y_train:")
print(train_balance)

# Contar o número de exemplos de cada classe em y_test
test_balance = y_test.value_counts()
print("\nBalanceamento em y_test:")
print(test_balance)





from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score
from sklearn.metrics import recall_score





# Criação de uma instância do classificador Naive Bayes Gaussiano
naive_churn = GaussianNB()
# Treinamento do classificador usando os dados de treinamento
naive_churn.fit(X_train, y_train)











# Fazer previsões para os dados de treino
y_pred_train = naive_churn.predict(X_train)
# Calcular a acurácia
accuracy = accuracy_score(y_train, y_pred_train)
print("Acurácia:", accuracy)











conf_matrix = confusion_matrix(y_train, y_pred_train)

# Definindo  nomes de classes
class_names = ['Churn', 'Não Churn']

# Plotando a matriz de confusão com Plotly
fig = ff.create_annotated_heatmap(
    z=conf_matrix,
    x=class_names,
    y=class_names,
    colorscale='Blues',
    showscale=True
)
fig.update_layout(
    title='Matriz de Confusão',
    xaxis_title='Predicted labels',
    yaxis_title='True labels',
    font=dict(
        family='Arial',
        size=12,
        color='black'
    )
)


conf_matrix = confusion_matrix(y_train, y_pred_train)

conf_matrix


69059/117950











recall = recall_score(y_train, y_pred_train)
print("Recall:", recall)











y_pred_test = naive_churn.predict(X_test)


accuracy = accuracy_score(y_test, y_pred_test)
recall = recall_score(y_test, y_pred_test)


print("Acurácia:", accuracy)
print("Recall:", recall)


conf_matrix = confusion_matrix(y_test, y_pred_test)

conf_matrix





# Visualizar os valores previstos
print("Valores Previstos:")
print(y_pred_test)


# Visualizar os valores reais
print("\nValores Reais:")
print(y_test)



