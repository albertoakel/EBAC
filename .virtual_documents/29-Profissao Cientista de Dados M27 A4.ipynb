














import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
from imblearn.over_sampling import SMOTE


base = pd.read_csv("CARRO_CLIENTES.csv", delimiter=',')


base








# verificando tipos de dados e represença de nulos
base.info()


# dropando a coluna de id que não necessitaremoss
base.drop(columns=['User ID'], inplace=True)


# verificando se na coluna categorica (gender) temos algum valor escrito errado
base['Gender'].unique()


base.describe()








# breve analise bivariada para conhecermos melhor nossos dados
contagem = pd.crosstab(base['Gender'], base['Purchased'])
contagem.plot(kind='bar', stacked=True)
plt.title('Distribuição de Compras por Gênero')
plt.xlabel('Gender')
plt.ylabel('Contagem')
plt.legend(title='Purchased', labels=['Não Comprou', 'Comprou'])
plt.show()





media_annual_salary = base.groupby('Purchased')['AnnualSalary'].mean()
print(media_annual_salary)





media_age = base.groupby('Purchased')['Age'].mean()
print(media_age)








# Substituir os valores da coluna 'GENDER' por números específicos utilizando o replace
gender_mapping = {'Male': 0, 'Female': 1}
base['Gender'] = base['Gender'].replace(gender_mapping)


base


correlation_matrix = base.corr()

# Plotando a matriz de correlação usando seaborn
plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1)
plt.title('Matriz de Correlação')
plt.show()





# Separando em X (variáveis de entrada) e Y (variável de saída)
X = base.drop('Purchased', axis=1)  # X contém todas as colunas exceto 'Purchased'
Y = base['Purchased']  # Y contém apenas a coluna 'Purchased'





base['Purchased'].value_counts()





# Separar em base de treino e teste (usando 80% para treino e 20% para teste)
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)














from sklearn.preprocessing import StandardScaler

# Inicializar StandardScaler
sc=StandardScaler()
#display(X_train.loc[0:10,1])

# Ajustando e transformando os dados de treino
X_train = sc.fit_transform(X_train)


# Transformando os dados de teste usando os parâmetros aprendidos dos dados de treino
X_test = sc.transform(X_test)


X_train[0:10,0]





# Balancear os dados de treinamento usando SMOTE
smote = SMOTE(random_state=42)
X_train_balanced, Y_train_balanced = smote.fit_resample(X_train, Y_train)





X_train_balanced


Y_train_balanced


X_test


Y_test





# Utilizaremos a skleran
from sklearn.linear_model import LogisticRegression





logistic_carro = LogisticRegression(random_state = 0)
# poderiamos adicionar max_iter = um valor. Ele controla o número máximo de vezes que o algoritmo itera sobre o conjunto de dados para encontrar os melhores coeficientes.


logistic_carro.fit(X_train_balanced, Y_train_balanced)


logistic_carro.intercept_


logistic_carro.coef_











previsoes = logistic_carro.predict(X_train_balanced)


relatorio = classification_report(Y_train_balanced, previsoes)
print("Relatório de Classificação:")
print(relatorio)





Y_pred_test = logistic_carro.predict(X_test)


relatorio = classification_report(Y_test, Y_pred_test)
print("Relatório de Classificação:")
print(relatorio)




















from sklearn.metrics import roc_curve, roc_auc_score, classification_report
fpr, tpr, thresholds = roc_curve(Y_test, Y_pred_test)

# Calcular a AUC
roc_auc = roc_auc_score(Y_test, Y_pred_test)
print("AUC: {:.2f}".format(roc_auc))


plt.figure()
plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic')
plt.legend(loc="lower right")
plt.show()
