





import seaborn as sns
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
import sklearn
#Scikit-learn é uma biblioteca popular de código aberto em Python para aprendizado de máquina. Ele fornece uma ampla gama de algoritmos de aprendizado supervisionado e não supervisionado, além de utilitários para pré-processamento de dados, seleção de modelos, avaliação de desempenho e muito mais.


df = pd.read_csv("CHURN_CREDIT_MOD08_PART3.csv", delimiter=',')

df.head(10)








df.select_dtypes(include=['number']).corr()











correlation_matrix = df.select_dtypes(include=['number']).corr()

# Plotar o mapa de calor da matriz de correlação
plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f", annot_kws={"size": 10})
plt.title('Matriz de Correlação')
plt.show()





























from sklearn.preprocessing import LabelEncoder

# Criando uma instância do Label Encoder
label_encoder = LabelEncoder()

# Aplicando o Label Encoder para a coluna "Genero" - ideal
df['Genero_encoded'] = label_encoder.fit_transform(df['Genero'])

# Aplicar o One Hot para a coluna "Pais" - Nesse caso não criamos instância
df = pd.get_dummies(df, columns=['Pais'], prefix='Pais', drop_first=True)
#pd.get_dummies(df, columns=['Pais'], prefix='Pais'): Esta função transforma a coluna "Pais" em várias colunas binárias (one-hot encoded)

print(df)








df.dtypes


for column in df.columns:
    if df[column].dtype == 'bool':
        df[column] = df[column].astype(int)
print(df)


# Vamos dropar as colunas com os atributos categóricos
df = df.drop(['Genero'], axis=1)
print(df)





df.corr()

















# Separar os dados em features (X) e o alvo (y)
X = df.drop('Churn', axis=1)  # Considerando que 'Churn' é a coluna a ser predita
y = df['Churn']


from sklearn.model_selection import train_test_split


# Separar os dados em conjuntos de treino e teste
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)
# O parâmetro 'test_size' determina a proporção dos dados que serão separados para teste (25% neste exemplo)
# O parâmetro 'random_state' é usado para garantir que a divisão seja reproduzível








X_train


X_test


y_train


y_test


print("Tamanho de X_train:", X_train.shape)


print("Tamanho de X_test:", X_test.shape)


print("Tamanho de y_train:", y_train.shape)


print("Tamanho de y_test:", y_test.shape)














churn_counts = df['Churn'].value_counts()
plt.figure(figsize=(8, 6))
churn_counts.plot(kind='bar', color=['blue', 'orange'])


# Calcular e imprimir as porcentagens dos valores na coluna 'churn'
print((df['Churn'].value_counts(normalize=True) * 100))














from imblearn.over_sampling import SMOTE

# Criar uma instância do SMOTE
smote = SMOTE(random_state=42)

# Aplicar o SMOTE aos dados de treinamento (X_train, y_train)
X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)

# Verificar a distribuição das classes após o balanceamento
print("Distribuição das classes após o balanceamento:")
print(y_train_balanced.value_counts())


train_balance = y_train_balanced.value_counts()
print("Balanceamento em y_train:")
print(train_balance)


y_train_balanced.to_csv('y_train_balanced.csv', index=False)


X_train_balanced.to_csv('X_train_balanced.csv', index=False)


y_test.to_csv('y_test.csv', index=False)


X_test.to_csv('X_test.csv', index=False)
